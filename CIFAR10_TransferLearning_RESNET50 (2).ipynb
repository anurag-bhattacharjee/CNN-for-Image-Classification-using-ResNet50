{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"1agGD7uP493Q","executionInfo":{"status":"ok","timestamp":1639296618171,"user_tz":420,"elapsed":2783,"user":{"displayName":"Anurag Bhattacharjee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18035335241611157928"}}},"outputs":[],"source":["#https://medium.com/@kenneth.ca95/a-guide-to-transfer-learning-with-keras-using-resnet50-a81a4a28084b\n","# Running the version as 1.x is optional, without that first line it will run the last version of tensorflow for Colab.\n","\n","import keras\n","import tensorflow as tf \n","from tensorflow import keras\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Flatten, Activation, BatchNormalization\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras.datasets import cifar10\n","from keras import datasets, layers, models\n","from keras import regularizers\n","\n","import pandas as pd\n","#from keras.utils import plot_model\n","from keras.utils.vis_utils import plot_model\n","#from keras.utils import np_utils\n","from keras import utils as np_utils\n","#from keras.utils import to_categorical\n","from tensorflow.keras.utils import to_categorical\n","pd.set_option('display.max_columns',None)#displaying long list of columns\n","pd.set_option('display.max_rows', None)#displaying long list of rows\n","pd.set_option('display.width', 1000)#width of window\n"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"4MYBDH6Kcxs7","outputId":"94507b18-dcb0-4440-dda8-e88131bd14b0","colab":{"base_uri":"https://localhost:8080/","height":130},"executionInfo":{"status":"error","timestamp":1639285468386,"user_tz":420,"elapsed":173,"user":{"displayName":"Anurag Bhattacharjee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18035335241611157928"}}},"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-1f60cfcff505>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    conda install tensorflow\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}],"source":["pip install tensorflow"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"MUEuZsobBTUF","executionInfo":{"status":"ok","timestamp":1639296739243,"user_tz":420,"elapsed":192,"user":{"displayName":"Anurag Bhattacharjee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18035335241611157928"}}},"outputs":[],"source":["# Load data\n","# CIFAR-10 is a dataset with 60000 32x32 colour images grouped in 10 classes, that means 6000 images per class. \n","# This is a dataset of 50,000 32x32 color training images and 10,000 test images, labeled over 10 categories.\n","# The categories are airplane, automobile, beer, cat, deer, dog, frog, horse, ship, truck. \n","# We can take advantage of the fact that these categories and a lot more are into the Imagenet collection.\n","# Loading the CIFAR-10 datasets\n","from keras.datasets import cifar10\n","\n"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"29Bq-NQmCDgS","executionInfo":{"status":"ok","timestamp":1639296742054,"user_tz":420,"elapsed":211,"user":{"displayName":"Anurag Bhattacharjee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18035335241611157928"}}},"outputs":[],"source":["# Preprocess data function\n","# Now that the data is loaded, we are going to build a preprocess function for the data. \n","# We have X as a numpy array of shape (m, 32, 32, 3) where m is the number of images, \n","# 32 and 32 the dimensions, and 3 is because we use color images (RGB). \n","# We have a set of X for training and a set of X for validation. \n","# Y is a numpy array of shape (m, ) that we want to be our labels. \n","# Since we work with 10 different categories, we make use of one-hot encoding with a \n","# function of Keras that makes our Y into a shape of (m, 10). That also applies for the validation.\n","\n","def preprocess_data(X,Y):\n","  X_p = keras.applications.resnet50.preprocess_input(X)\n","  Y_p = keras.utils.to_categorical(Y,10)\n","  return X_p, Y_p\n","  "]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q4qZ9aHTEQUp","outputId":"0b4483db-c530-4f97-f3bf-cecae943fcff","executionInfo":{"status":"ok","timestamp":1639296751170,"user_tz":420,"elapsed":6863,"user":{"displayName":"Anurag Bhattacharjee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18035335241611157928"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170500096/170498071 [==============================] - 4s 0us/step\n","170508288/170498071 [==============================] - 4s 0us/step\n","x_train shape: (50000, 32, 32, 3)\n","y_train shape: (50000, 1)\n"]}],"source":["# load and split data\n","# The data, split between train and test sets:\n","\n","#(x_train, y_train), (x_test, y_test) = K.datasets.cifar10.load_data()\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","print('x_train shape:', x_train.shape)\n","print('y_train shape:', y_train.shape)\n"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aAs88uCaFMc3","outputId":"b950d8f0-5a1d-4617-8346-24f10711dccc","executionInfo":{"status":"ok","timestamp":1639296753994,"user_tz":420,"elapsed":612,"user":{"displayName":"Anurag Bhattacharjee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18035335241611157928"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["x_train shape: (50000, 32, 32, 3)\n","y_train shape: (50000, 10)\n"]}],"source":["# Preprocess data\n","## Next, we are going to call our function with the parameters loaded from the CIFAR10 database.\n","\n","x_train, y_train = preprocess_data(x_train, y_train)\n","x_test, y_test = preprocess_data(x_test, y_test)\n","print('x_train shape:', x_train.shape)\n","print('y_train shape:', y_train.shape)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vDEpJYeWGK46","outputId":"9da57b19-bdbe-441d-99bc-6f1c35fce5ae","executionInfo":{"status":"ok","timestamp":1639296758611,"user_tz":420,"elapsed":2384,"user":{"displayName":"Anurag Bhattacharjee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18035335241611157928"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n","94773248/94765736 [==============================] - 1s 0us/step\n","94781440/94765736 [==============================] - 1s 0us/step\n"]}],"source":["# Using weights of a trained neural network\n","# A pretrained model from the Keras Applications has the advantage of allow you to use weights that\n","# are already calibrated to make predictions. In this case, we use the weights from Imagenet \n","# and the network is a ResNet50. The option include_top=False allows feature extraction by removing \n","# the last dense layers. This let us control the output and input of the model.\n","\n","input_t = keras.Input(shape=(32,32,3))\n","res_model = keras.applications.ResNet50(include_top=False,\n","                                    weights=\"imagenet\",\n","                                    input_tensor=input_t)\n"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"hlyKjCtPH3m3","executionInfo":{"status":"ok","timestamp":1639296762707,"user_tz":420,"elapsed":193,"user":{"displayName":"Anurag Bhattacharjee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18035335241611157928"}}},"outputs":[],"source":["# In this case, we ‘freeze’ all layers except for the last block of the ResNet50.\n","\n","for layer in res_model.layers[:143]:\n","  layer.trainable=False\n","  "]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JdixTKJ7I10V","outputId":"447593b6-2b95-48f8-c45b-d291fb13c190","executionInfo":{"status":"ok","timestamp":1639296765420,"user_tz":420,"elapsed":179,"user":{"displayName":"Anurag Bhattacharjee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18035335241611157928"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["0 input_1 - False\n","1 conv1_pad - False\n","2 conv1_conv - False\n","3 conv1_bn - False\n","4 conv1_relu - False\n","5 pool1_pad - False\n","6 pool1_pool - False\n","7 conv2_block1_1_conv - False\n","8 conv2_block1_1_bn - False\n","9 conv2_block1_1_relu - False\n","10 conv2_block1_2_conv - False\n","11 conv2_block1_2_bn - False\n","12 conv2_block1_2_relu - False\n","13 conv2_block1_0_conv - False\n","14 conv2_block1_3_conv - False\n","15 conv2_block1_0_bn - False\n","16 conv2_block1_3_bn - False\n","17 conv2_block1_add - False\n","18 conv2_block1_out - False\n","19 conv2_block2_1_conv - False\n","20 conv2_block2_1_bn - False\n","21 conv2_block2_1_relu - False\n","22 conv2_block2_2_conv - False\n","23 conv2_block2_2_bn - False\n","24 conv2_block2_2_relu - False\n","25 conv2_block2_3_conv - False\n","26 conv2_block2_3_bn - False\n","27 conv2_block2_add - False\n","28 conv2_block2_out - False\n","29 conv2_block3_1_conv - False\n","30 conv2_block3_1_bn - False\n","31 conv2_block3_1_relu - False\n","32 conv2_block3_2_conv - False\n","33 conv2_block3_2_bn - False\n","34 conv2_block3_2_relu - False\n","35 conv2_block3_3_conv - False\n","36 conv2_block3_3_bn - False\n","37 conv2_block3_add - False\n","38 conv2_block3_out - False\n","39 conv3_block1_1_conv - False\n","40 conv3_block1_1_bn - False\n","41 conv3_block1_1_relu - False\n","42 conv3_block1_2_conv - False\n","43 conv3_block1_2_bn - False\n","44 conv3_block1_2_relu - False\n","45 conv3_block1_0_conv - False\n","46 conv3_block1_3_conv - False\n","47 conv3_block1_0_bn - False\n","48 conv3_block1_3_bn - False\n","49 conv3_block1_add - False\n","50 conv3_block1_out - False\n","51 conv3_block2_1_conv - False\n","52 conv3_block2_1_bn - False\n","53 conv3_block2_1_relu - False\n","54 conv3_block2_2_conv - False\n","55 conv3_block2_2_bn - False\n","56 conv3_block2_2_relu - False\n","57 conv3_block2_3_conv - False\n","58 conv3_block2_3_bn - False\n","59 conv3_block2_add - False\n","60 conv3_block2_out - False\n","61 conv3_block3_1_conv - False\n","62 conv3_block3_1_bn - False\n","63 conv3_block3_1_relu - False\n","64 conv3_block3_2_conv - False\n","65 conv3_block3_2_bn - False\n","66 conv3_block3_2_relu - False\n","67 conv3_block3_3_conv - False\n","68 conv3_block3_3_bn - False\n","69 conv3_block3_add - False\n","70 conv3_block3_out - False\n","71 conv3_block4_1_conv - False\n","72 conv3_block4_1_bn - False\n","73 conv3_block4_1_relu - False\n","74 conv3_block4_2_conv - False\n","75 conv3_block4_2_bn - False\n","76 conv3_block4_2_relu - False\n","77 conv3_block4_3_conv - False\n","78 conv3_block4_3_bn - False\n","79 conv3_block4_add - False\n","80 conv3_block4_out - False\n","81 conv4_block1_1_conv - False\n","82 conv4_block1_1_bn - False\n","83 conv4_block1_1_relu - False\n","84 conv4_block1_2_conv - False\n","85 conv4_block1_2_bn - False\n","86 conv4_block1_2_relu - False\n","87 conv4_block1_0_conv - False\n","88 conv4_block1_3_conv - False\n","89 conv4_block1_0_bn - False\n","90 conv4_block1_3_bn - False\n","91 conv4_block1_add - False\n","92 conv4_block1_out - False\n","93 conv4_block2_1_conv - False\n","94 conv4_block2_1_bn - False\n","95 conv4_block2_1_relu - False\n","96 conv4_block2_2_conv - False\n","97 conv4_block2_2_bn - False\n","98 conv4_block2_2_relu - False\n","99 conv4_block2_3_conv - False\n","100 conv4_block2_3_bn - False\n","101 conv4_block2_add - False\n","102 conv4_block2_out - False\n","103 conv4_block3_1_conv - False\n","104 conv4_block3_1_bn - False\n","105 conv4_block3_1_relu - False\n","106 conv4_block3_2_conv - False\n","107 conv4_block3_2_bn - False\n","108 conv4_block3_2_relu - False\n","109 conv4_block3_3_conv - False\n","110 conv4_block3_3_bn - False\n","111 conv4_block3_add - False\n","112 conv4_block3_out - False\n","113 conv4_block4_1_conv - False\n","114 conv4_block4_1_bn - False\n","115 conv4_block4_1_relu - False\n","116 conv4_block4_2_conv - False\n","117 conv4_block4_2_bn - False\n","118 conv4_block4_2_relu - False\n","119 conv4_block4_3_conv - False\n","120 conv4_block4_3_bn - False\n","121 conv4_block4_add - False\n","122 conv4_block4_out - False\n","123 conv4_block5_1_conv - False\n","124 conv4_block5_1_bn - False\n","125 conv4_block5_1_relu - False\n","126 conv4_block5_2_conv - False\n","127 conv4_block5_2_bn - False\n","128 conv4_block5_2_relu - False\n","129 conv4_block5_3_conv - False\n","130 conv4_block5_3_bn - False\n","131 conv4_block5_add - False\n","132 conv4_block5_out - False\n","133 conv4_block6_1_conv - False\n","134 conv4_block6_1_bn - False\n","135 conv4_block6_1_relu - False\n","136 conv4_block6_2_conv - False\n","137 conv4_block6_2_bn - False\n","138 conv4_block6_2_relu - False\n","139 conv4_block6_3_conv - False\n","140 conv4_block6_3_bn - False\n","141 conv4_block6_add - False\n","142 conv4_block6_out - False\n","143 conv5_block1_1_conv - True\n","144 conv5_block1_1_bn - True\n","145 conv5_block1_1_relu - True\n","146 conv5_block1_2_conv - True\n","147 conv5_block1_2_bn - True\n","148 conv5_block1_2_relu - True\n","149 conv5_block1_0_conv - True\n","150 conv5_block1_3_conv - True\n","151 conv5_block1_0_bn - True\n","152 conv5_block1_3_bn - True\n","153 conv5_block1_add - True\n","154 conv5_block1_out - True\n","155 conv5_block2_1_conv - True\n","156 conv5_block2_1_bn - True\n","157 conv5_block2_1_relu - True\n","158 conv5_block2_2_conv - True\n","159 conv5_block2_2_bn - True\n","160 conv5_block2_2_relu - True\n","161 conv5_block2_3_conv - True\n","162 conv5_block2_3_bn - True\n","163 conv5_block2_add - True\n","164 conv5_block2_out - True\n","165 conv5_block3_1_conv - True\n","166 conv5_block3_1_bn - True\n","167 conv5_block3_1_relu - True\n","168 conv5_block3_2_conv - True\n","169 conv5_block3_2_bn - True\n","170 conv5_block3_2_relu - True\n","171 conv5_block3_3_conv - True\n","172 conv5_block3_3_bn - True\n","173 conv5_block3_add - True\n","174 conv5_block3_out - True\n"]}],"source":["# We can check that we did it correctly with:\n","# False means that the layer is ‘freezed’ or is not trainable and \n","# True that when we run our model, the weights are going to be adjusted.\n","\n","for i, layer in enumerate(res_model.layers):\n","  print(i,layer.name,\"-\",layer.trainable)\n","  "]},{"cell_type":"code","source":["# Creating a sequential model and adding layers to it\n","# Add Flatten and Dense layers on top of Resnet\n","# Now, we need to connect our pretrained model with the new layers \n","# of our model. We can use global pooling or a flatten layer to connect \n","# the dimensions of the previous layers with the new layers.\n","\n","model = Sequential()\n","\n","model.add(layers.Conv2D(32, (3,3), padding='same', activation='relu', input_shape=(32,32,3)))\n","model.add(layers.BatchNormalization())\n","model.add(layers.Conv2D(32, (3,3), padding='same', activation='relu'))\n","model.add(layers.BatchNormalization())\n","model.add(layers.MaxPooling2D(pool_size=(2,2)))\n","model.add(layers.Dropout(0.3))\n","\n","model.add(layers.Conv2D(64, (3,3), padding='same', activation='relu'))\n","model.add(layers.BatchNormalization())\n","model.add(layers.Conv2D(64, (3,3), padding='same', activation='relu'))\n","model.add(layers.BatchNormalization())\n","model.add(layers.MaxPooling2D(pool_size=(2,2)))\n","model.add(layers.Dropout(0.5))\n","\n","model.add(layers.Conv2D(128, (3,3), padding='same', activation='relu'))\n","model.add(layers.BatchNormalization())\n","model.add(layers.Conv2D(128, (3,3), padding='same', activation='relu'))\n","model.add(layers.BatchNormalization())\n","model.add(layers.MaxPooling2D(pool_size=(2,2)))\n","model.add(layers.Dropout(0.4))\n","\n","model.add(layers.Flatten())\n","model.add(layers.Dense(128, activation='relu'))\n","model.add(layers.BatchNormalization())\n","model.add(layers.Dropout(0.3))\n","model.add(layers.Dense(10, activation='softmax'))"],"metadata":{"id":"mFKJrzr1jsGA","executionInfo":{"status":"ok","timestamp":1639296832341,"user_tz":420,"elapsed":410,"user":{"displayName":"Anurag Bhattacharjee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18035335241611157928"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# Compile model and train\n","model.compile(optimizer='adam', loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])"],"metadata":{"id":"OXksyMu9kA79","executionInfo":{"status":"ok","timestamp":1639296835014,"user_tz":420,"elapsed":185,"user":{"displayName":"Anurag Bhattacharjee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18035335241611157928"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["# Results\n","history = model.fit(x_train, y_train, batch_size=64, epochs=25,\n","                    validation_data=(x_test,y_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":380},"id":"jH5bW-2jkY8H","executionInfo":{"status":"error","timestamp":1639296869434,"user_tz":420,"elapsed":4705,"user":{"displayName":"Anurag Bhattacharjee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18035335241611157928"}},"outputId":"aa7cdb6a-6030-44b6-866c-00e647ce52bc"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/25\n"," 63/782 [=>............................] - ETA: 5:43 - loss: 2.3763 - accuracy: 0.2517"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-03519e421bd6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m history = model.fit(x_train, y_train, batch_size=64, epochs=25,\n\u001b[0;32m----> 3\u001b[0;31m                     validation_data=(x_test,y_test))\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3131\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1960\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kqRQQn99nlKt","executionInfo":{"status":"ok","timestamp":1639295878343,"user_tz":420,"elapsed":18,"user":{"displayName":"Anurag Bhattacharjee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18035335241611157928"}},"outputId":"f6764e69-2e19-4c56-b892-2175247e251c"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_4\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_6 (Conv2D)           (None, 32, 32, 32)        896       \n","                                                                 \n"," batch_normalization_17 (Bat  (None, 32, 32, 32)       128       \n"," chNormalization)                                                \n","                                                                 \n"," conv2d_7 (Conv2D)           (None, 32, 32, 32)        9248      \n","                                                                 \n"," batch_normalization_18 (Bat  (None, 32, 32, 32)       128       \n"," chNormalization)                                                \n","                                                                 \n"," max_pooling2d_3 (MaxPooling  (None, 16, 16, 32)       0         \n"," 2D)                                                             \n","                                                                 \n"," dropout_12 (Dropout)        (None, 16, 16, 32)        0         \n","                                                                 \n"," conv2d_8 (Conv2D)           (None, 16, 16, 64)        18496     \n","                                                                 \n"," batch_normalization_19 (Bat  (None, 16, 16, 64)       256       \n"," chNormalization)                                                \n","                                                                 \n"," conv2d_9 (Conv2D)           (None, 16, 16, 64)        36928     \n","                                                                 \n"," batch_normalization_20 (Bat  (None, 16, 16, 64)       256       \n"," chNormalization)                                                \n","                                                                 \n"," max_pooling2d_4 (MaxPooling  (None, 8, 8, 64)         0         \n"," 2D)                                                             \n","                                                                 \n"," dropout_13 (Dropout)        (None, 8, 8, 64)          0         \n","                                                                 \n"," conv2d_10 (Conv2D)          (None, 8, 8, 128)         73856     \n","                                                                 \n"," batch_normalization_21 (Bat  (None, 8, 8, 128)        512       \n"," chNormalization)                                                \n","                                                                 \n"," conv2d_11 (Conv2D)          (None, 8, 8, 128)         147584    \n","                                                                 \n"," batch_normalization_22 (Bat  (None, 8, 8, 128)        512       \n"," chNormalization)                                                \n","                                                                 \n"," max_pooling2d_5 (MaxPooling  (None, 4, 4, 128)        0         \n"," 2D)                                                             \n","                                                                 \n"," dropout_14 (Dropout)        (None, 4, 4, 128)         0         \n","                                                                 \n"," flatten_3 (Flatten)         (None, 2048)              0         \n","                                                                 \n"," dense_12 (Dense)            (None, 128)               262272    \n","                                                                 \n"," batch_normalization_23 (Bat  (None, 128)              512       \n"," chNormalization)                                                \n","                                                                 \n"," dropout_15 (Dropout)        (None, 128)               0         \n","                                                                 \n"," dense_13 (Dense)            (None, 10)                1290      \n","                                                                 \n","=================================================================\n","Total params: 552,874\n","Trainable params: 551,722\n","Non-trainable params: 1,152\n","_________________________________________________________________\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"CIFAR10_TransferLearning_RESNET50.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":0}